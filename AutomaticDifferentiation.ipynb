{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomaticDifferentiation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dayn9/LearnTensorFlow/blob/master/AutomaticDifferentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e1nZ6oANvbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdVXdVwASkzY",
        "colab_type": "text"
      },
      "source": [
        "**Gradient Tapes**\n",
        "\n",
        "computes the gradient of a computatation with respect to it's input variables\n",
        "\n",
        "all operations excecuted get stored onto a \"Tape\"\n",
        "\n",
        "ERROR: thrown because resources held by Tape are released as soon as _.gradient() is called\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lReaevkHSd_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "fe278f7b-d54c-4447-c79d-67057bf4c0be"
      },
      "source": [
        "x = tf.ones((2, 2))\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x)\n",
        "  print(x)\n",
        "  y = tf.reduce_sum(x) # adds up all the values in the 2D array\n",
        "  print(y)\n",
        "  z = tf.multiply(y, y)\n",
        "  print(z)\n",
        "  \n",
        "dz_dx = t.gradient(z, x) # derivative of z with respect to x\n",
        "print(dz_dx)\n",
        "  \n",
        "dz_dy = t.gradient(z, y) # derivative of z with respect to y\n",
        "print(dz_dy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n",
            "tf.Tensor(16.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[8. 8.]\n",
            " [8. 8.]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c6d630512825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz_dx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdz_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# derivative of z with respect to y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \"\"\"\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[1;32m    912\u001b[0m                          \"non-persistent tapes.\")\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Sr5yw6TktS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d6f9c674-8144-4c7d-b06e-f1a6be04de6c"
      },
      "source": [
        "x = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape(persistent = True) as t:\n",
        "  t.watch(x)\n",
        "  print(x)\n",
        "  y = x * x\n",
        "  print(y)\n",
        "  z = y * y\n",
        "  print(z)\n",
        "  \n",
        "dz_dx = t.gradient(z, x) # derivative of z with respect to x\n",
        "print(dz_dx)\n",
        "  \n",
        "dz_dy = t.gradient(z, y) # derivative of z with respect to y\n",
        "print(dz_dy)\n",
        "\n",
        "del t # Drop the Ref"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n",
            "tf.Tensor(9.0, shape=(), dtype=float32)\n",
            "tf.Tensor(81.0, shape=(), dtype=float32)\n",
            "tf.Tensor(108.0, shape=(), dtype=float32)\n",
            "tf.Tensor(18.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrWHyFS3WwW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "48dabde4-e575-43f1-ffe1-1eb40716beae"
      },
      "source": [
        "def f(x, y):\n",
        "  out = 1.0\n",
        "  for i in range(y):\n",
        "    if i > 1 and i < 5:\n",
        "      out = tf.multiply(out, x)\n",
        "      print(out)\n",
        "  return out\n",
        "\n",
        "def grad(x, y):\n",
        "  with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    out = f(x,y)\n",
        "  return t.gradient(out, x)\n",
        "\n",
        "x = tf.convert_to_tensor(2.0)\n",
        "\n",
        "print(grad(x, 6))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n",
            "tf.Tensor(8.0, shape=(), dtype=float32)\n",
            "tf.Tensor(12.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srSHPIiFXrHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fdb3acb8-e1f5-4fb5-ba76-8b7a536f6f4e"
      },
      "source": [
        "x = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as t1:\n",
        "  with tf.GradientTape() as t2:\n",
        "    y = x * x * x\n",
        "    print(y)\n",
        "  \n",
        "  dy_dx = t2.gradient(y, x)\n",
        "  print(dy_dx)\n",
        "d2y_d2x = t1.gradient(dy_dx, x)\n",
        "print(d2y_d2x)\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(3.0, shape=(), dtype=float32)\n",
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSEsVzAKY2A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}